{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mass Merge of Relevant Data\n",
    "\n",
    "In the below file, the data collected through various means thus far in this project will be merged and documented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import requests\n",
    "import unicodedata\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "iso_data = pd.read_json('../js_files/iso6393.json')\n",
    "glottolog_data = pd.read_csv('../csv_files/glottolog_status_data_with_links.csv', index_col = 0)\n",
    "wiki_data = pd.read_csv('../csv_files/wiki_languages_most_recent.csv', index_col = 0)\n",
    "lat_long_dialects = pd.read_csv('../csv_files/languages_and_dialects_geo.csv', index_col = 0)\n",
    "languoid_data = pd.read_csv('../csv_files/glottolog_languoid.csv', index_col = 0)\n",
    "extinct_data = pd.read_csv('../csv_files/Extinct languages - DATA SUMMARY.csv', index_col = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "glottolog_data = glottolog_data.reset_index()\n",
    "# glottolog_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['iso6393', 'glottocode', 'aes_status'], dtype='object')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../csv_files/glottolog_status_data.csv', index_col = 0).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Location Later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you see the Glottolog Data (ISO 639-3 Code, Glottocode, Agglomerated Endangerement Status, and Wikipedia page URL) merged to the ISO Data (Language Name, Language Type, Language Scope, ISO 639-3 Code). \n",
    "\n",
    "Glottolog Data Source:\n",
    "* Glottolog Data was gathered for the ISO 639-3 Code, Glottocode, and Agglomerated Endangerement Status from XXX, and can be seen in ../csv_files/glottolog_status_data. \n",
    "* The above data frame was then expanded into ../csv_files/glottolog_status_data_with_links by adding the Wikipedia page URL to the data frame using the web scraper in ../scrapers_organized/glottolog_scraper.ipynb\n",
    "\n",
    "ISO Data Source:\n",
    "* ISO Data was downloaded from the iso6393.js file listed in the following GitHub repository: https://github.com/wooorm/iso-639-3. This file can be seen in ../js_files/iso6393.js\n",
    "* The above file was then converted to a .json file using regular expressions, which can be seen in ../js_files/iso6393.json. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "iso_glotto_data = pd.merge(iso_data, glottolog_data, how = 'left', on = 'iso6393')\n",
    "iso_glotto_data = iso_glotto_data.drop_duplicates(subset = 'iso6393')\n",
    "print(len(iso_glotto_data) == len(iso_data) if len(iso_data) > len(glottolog_data) else len(iso_glotto_data) == len(glottolog_data))\n",
    "# iso_glotto_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you see the previously merged dataframe (iso_glotto_data) merged to the Wikipedia Data.\n",
    "\n",
    "Wikipedia Data Source:\n",
    "* All data obtained from Wikipedia in this data frame was scraped by the web scraper in the ../scrapers_organized/wikipedia_scraper.ipynb file. This gathered the following fields from the infobox in the top right side of the page, where applicable:\n",
    "    * Language Name (as listed on Wikipedia)\n",
    "    * Language Family \n",
    "    * Language Dialects \n",
    "    * ISO 639-3 Code\n",
    "    * Glottocode \n",
    "    * Number of Speakers \n",
    "    * Regions wherein the language is spoken \n",
    "    * Nations wherein the language is an official language \n",
    "    * Nations wherein the language is a recognized minority language \n",
    "    * The Wikipedia URL used the access the page\n",
    "\n",
    "Note: The name column is preserved from the ISO 639-3 .json file using a left merge, since this represents the internationally recognized name of a given language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "iso_glotto_wiki_data = pd.merge(iso_glotto_data, wiki_data, how = 'left', on = ['iso6393', 'glottocode', 'Wikipedia_Url'])\n",
    "iso_glotto_wiki_data = iso_glotto_wiki_data.drop_duplicates(subset = 'iso6393')\n",
    "print(len(iso_glotto_wiki_data) == len(iso_glotto_data))\n",
    "# iso_glotto_wiki_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you see the previously merged dataframe (iso_glotto_wiki_data) merged to the Latitude/Longitude Data \n",
    "\n",
    "Latitude/Longitude Data Source:\n",
    "* The Latitude/Longitude Data can be seen in the ../csv_files/languages_and_dialects_geo.csv file. This was downloaded from Glottolog and can be found on the following page: https://glottolog.org/meta/downloads. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_long_dialects = lat_long_dialects.reset_index()\n",
    "lat_long_dialects = lat_long_dialects.rename(columns = {'isocodes': 'iso6393'})\n",
    "# lat_long_dialects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "iso_glotto_wiki_lat_long_data = pd.merge(iso_glotto_wiki_data, lat_long_dialects, how = 'left', on = ['iso6393', 'glottocode', 'name'])\n",
    "print(len(iso_glotto_wiki_lat_long_data) == len(iso_glotto_wiki_data))\n",
    "# iso_glotto_wiki_lat_long_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you see the previously merge dataframe (iso_glotto_wiki_lat_long_data) merged with Glottolog's relevant 'Languoid' data, which describes the information listed below about any language in their database. This was acquired via download of the glottolog_languoid.csv.zip file found at the following page: https://glottolog.org/meta/downloads. \n",
    "\n",
    "Languoid Information:\n",
    "* Glottocode \n",
    "* Glottolog's Family ID for the family of a given language \n",
    "* Glottolog's Parent ID for the parent language of a given language \n",
    "* The name of a given language (as listed by Glottolog)\n",
    "* Glottolog's Bookkeeping value \n",
    "    * If this value is true, the languoid listed is not regarded as a 'real languoid' by Glottolog's editors, but has been given a glottocode for bookkeeping purposes. \n",
    "* The level of a given language \n",
    "* The Latitude and Longitude values of a given language \n",
    "* The ISO 639-3 Code\n",
    "* A description and markup description for a given language\n",
    "* A count of child families, child lanuages, and child dialects of a given language\n",
    "* IDs of nations where a language is spoken. \n",
    "\n",
    "More information about any of the above descriptors can be found on the following page: \n",
    "Glottolog 5.0.\n",
    "Leipzig: Max Planck Institute for Evolutionary Anthropology.\n",
    "https://doi.org/10.5281/zenodo.8131084\n",
    "(Available online at http://glottolog.org, Accessed on 2024-03-11.)\n",
    "\n",
    "Note: Since the macroarea is not listed in this file, but is listed in the lat_long_dialects file, the latter is not rendered redundant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "languoid_data = languoid_data.reset_index()\n",
    "languoid_data = languoid_data.rename(columns = {'id': 'glottocode', 'iso639P3code': 'iso6393'})\n",
    "# languoid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "iso_glotto_wiki_lat_long_languoid_data = pd.merge(iso_glotto_wiki_lat_long_data, languoid_data, how = 'left', on = ['iso6393', 'glottocode', 'level', 'latitude', 'longitude'])\n",
    "iso_glotto_wiki_lat_long_languoid_data['name'] = iso_glotto_wiki_lat_long_languoid_data['name_x'] if iso_glotto_wiki_lat_long_languoid_data['name_x'].notnull().all() else iso_glotto_wiki_lat_long_languoid_data['name_y']\n",
    "iso_glotto_wiki_lat_long_languoid_data = iso_glotto_wiki_lat_long_languoid_data.drop(columns = ['name_x', 'name_y'])\n",
    "print(len(iso_glotto_wiki_lat_long_languoid_data) == len(iso_glotto_wiki_lat_long_data))\n",
    "# iso_glotto_wiki_lat_long_languoid_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you see the previous dataframe (iso_glotto_wiki_lat_long_languoid_data) merged with data on extinct languages, as determined by UNESCO. This data can be seen in ../csv_files/extinct_languages_with_info.csv. This was downloaded from the following page: https://www.theguardian.com/news/datablog/2011/apr/15/language-extinct-endangered. Although outdated, this provides more specific information on speakers of many extinct and endangered languages - which is the focus of this project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "extinct_data = extinct_data.reset_index()\n",
    "extinct_data = extinct_data.rename(columns = {'Name in English': 'name'})\n",
    "# extinct_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "iso_glotto_wiki_lat_long_languoid_extinct_data = pd.merge(iso_glotto_wiki_lat_long_languoid_data, extinct_data, how = 'left', on = ['name'])\n",
    "iso_glotto_wiki_lat_long_languoid_extinct_data = iso_glotto_wiki_lat_long_languoid_extinct_data.drop_duplicates(subset = 'iso6393')\n",
    "print(len(iso_glotto_wiki_lat_long_languoid_extinct_data) == len(iso_glotto_wiki_lat_long_languoid_data))\n",
    "# iso_glotto_wiki_lat_long_languoid_extinct_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_glotto_wiki_lat_long_languoid_extinct_data.to_csv('../csv_files/mass_merge.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
