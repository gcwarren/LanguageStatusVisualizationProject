{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glottolog Scraper\n",
    "\n",
    "This file takes information from the downloaded glottolog files to obtain a glottocode and scrapes the corresponding Wikipedia link from that languages page on Glottolog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import numpy as py\n",
    "\n",
    "status_data = pd.read_csv('../csv_files/glottolog_status_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7590/7590 [00:00<00:00, 4271403.11it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_links(): \n",
    "    link_base = 'https://glottolog.org/resource/languoid/id/'\n",
    "    ids = pd.read_csv('../docs/master_merge.csv')['glottocode'].values\n",
    "\n",
    "    links = []\n",
    "    for i in tqdm(ids):\n",
    "        links.append(link_base + i)\n",
    "    return links\n",
    "\n",
    "links = get_links()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7590/7590 [1:58:38<00:00,  1.07it/s]   \n"
     ]
    }
   ],
   "source": [
    "# FILEPATH: /Users/gracewarren/LanguageStatusVisualizationProject/ipynb_files/glottolog_scraper.ipynb\n",
    "# new_data = pd.DataFrame(columns = ['glottocode', 'aes_status'])\n",
    "\n",
    "for link in tqdm(links):\n",
    "    page = requests.get(link)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    aes_status = soup.find('dt', string='AES status:')\n",
    "    if aes_status is not None:\n",
    "        status_data.loc[status_data['glottocode'] == link.split('/')[-1], 'aes_status'] = aes_status.find_next_sibling('dd').string\n",
    "    else:\n",
    "        status_data.loc[status_data['glottocode'] == link.split('/')[-1], 'aes_status'] = 'N/A'\n",
    "        \n",
    "    wiki_link = soup.find('a', title='Wikipedia')\n",
    "    # print(wiki_link['href'])\n",
    "    if wiki_link is not None:\n",
    "        \n",
    "        status_data.loc[status_data['glottocode'] == link.split('/')[-1], 'Wikipedia_Url'] = wiki_link['href']\n",
    "    else:\n",
    "        status_data.loc[status_data['glottocode'] == link.split('/')[-1], 'Wikipedia_Url'] = ''\n",
    "\n",
    "status_data.to_csv('../csv_files/glottolog_status_data_with_links.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
